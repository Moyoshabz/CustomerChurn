# -*- coding: utf-8 -*-
"""Data_Mining_Group_1_Customer_Churn

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NJnBAzfGBnd3XQKlDccsoljKN9mZ66Q_

#Data Preprocessing
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import sklearn

file_url = "https://raw.githubusercontent.com/Moyoshabz/CustomerChurn/main/Telco_Customer_Churn.csv"
df = pd.read_csv(file_url)

print(df.head())

print(df.isnull().sum())

df.info()

# Data Validation - Checking for NaNs
nan_rows = df[df.isnull().any(axis=1)]
print(nan_rows)

#dropping unwanted columns
df.drop(['customerID'], axis=1, inplace=True)

#Converting the datatype for the TotalCharge from object to float
df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')
df.drop('TotalCharges', axis=1, inplace=True)

#EDA
Categorical_features = ['Contract', 'PaymentMethod', 'TechSupport', 'gender']
n_features = len(Categorical_features)

# Creating a subplot grid
fig, axes = plt.subplots(2, 2, figsize=(14, 8))
axes = axes.flatten()  # flatten 2D array to 1D for easy looping

for i, col in enumerate(Categorical_features):
    sns.countplot(data=df, x=col, hue='Churn', palette='Set2', ax=axes[i])
    axes[i].set_title(f'Churn by {col}')
    axes[i].set_xlabel(col)
    axes[i].set_ylabel("Count")
    axes[i].tick_params(axis='x', rotation=45)

plt.tight_layout()
plt.show()

#Encoding the binary columns in the dataset
from sklearn.preprocessing import LabelEncoder, StandardScaler
binary_cols = ['gender', 'Partner', 'Dependents', 'PhoneService', 'PaperlessBilling']
for col in binary_cols:
    df[col] = LabelEncoder().fit_transform(df[col])

# Encoding the columns with multiple categories
df = pd.get_dummies(df, columns=[
    'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup',
    'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies',
    'Contract', 'PaymentMethod'
], drop_first=True)

scaler = StandardScaler()
df[['tenure', 'MonthlyCharges']] = scaler.fit_transform(df[['tenure', 'MonthlyCharges']])

df['Churn'] = LabelEncoder().fit_transform(df['Churn'])

"""# Data Visualization"""

#Features Correlated with Churn before Prediction
correlation_matrix = df.corr()
plt.figure(figsize=(12,8))
sns.heatmap(correlation_matrix[['Churn']].sort_values('Churn', ascending=False),
            annot=True, cmap='coolwarm')
plt.title('Feature Correlation with Churn')
plt.show()

"""##Insight

Top 5 Churn Drivers:
1. InternetService(Fibre Optics = 0.31)
2. PaymentMethod_ElectronicCheck = 0.3
3. MonthlyCharges =0.19
4. PaperlessBilling =0.19
5. Senior Citizen =0.15
"""

#Understanding how tenure impact customer churn
plt.figure(figsize=(8, 5))
sns.boxplot(x='Churn', y='tenure', data=df)
plt.title("Tenure Distribution by Churn Status")
plt.show()

"""### Insight
Customers with shorter tensure churn more
"""

plt.figure(figsize=(8, 5))
sns.barplot(x='Contract_One year', y='Churn', data=df, ci=None)
plt.title("Churn Rate by Contract Type")
plt.show()

"""### Insight
Month-to-month contracts have higher churn rates than yearly contracts.
"""

#Handling class imbalanced, first we will observe the churn target column
print(df['Churn'].value_counts())

"""#Model Building"""

from sklearn.model_selection import train_test_split
X = df.drop('Churn', axis=1)
y = df['Churn']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

#standard features
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

from imblearn.over_sampling import SMOTE
smote = SMOTE(random_state=42)
X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)

from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, f1_score
def evaluate_model(model, X_test, y_test):
    try:
        if 'tensorflow' in str(type(model)).lower():
            y_prob = model.predict(X_test).ravel()
            y_pred = (y_prob >= 0.5).astype(int)
        else:
            y_pred = model.predict(X_test)
            if hasattr(model, 'predict_proba'):
                y_prob = model.predict_proba(X_test)[:, 1]
            else:
                y_prob = model.decision_function(X_test)

        print("Confusion Matrix:")
        print(confusion_matrix(y_test, y_pred))
        print("\nClassification Report:")
        print(classification_report(y_test, y_pred))
        print("ROC AUC Score:", roc_auc_score(y_test, y_prob))

    except Exception as e:
        print("Error during evaluation:", e)

#Logistic regression
from sklearn.linear_model import LogisticRegression
lr = LogisticRegression(class_weight='balanced', random_state=42, max_iter=1000)
lr.fit(X_train_resampled, y_train_resampled)
evaluate_model(lr, X_test, y_test)

#Decision Tree
from sklearn.tree import DecisionTreeClassifier
dt = DecisionTreeClassifier(class_weight='balanced', random_state=42)
dt.fit(X_train_resampled, y_train_resampled)
evaluate_model(dt, X_test, y_test)

#Random Forest
from sklearn.ensemble import RandomForestClassifier
rf = RandomForestClassifier(class_weight='balanced', random_state=42)
rf.fit(X_train_resampled, y_train_resampled)
evaluate_model(rf, X_test, y_test)

#Building the Neural Network
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping

# Setting seeds
np.random.seed(42)
tf.random.set_seed(42)

early_stop = EarlyStopping(patience=5, restore_best_weights=True)


model = Sequential([
    Dense(64, input_shape=(X_train_resampled.shape[1],), activation='relu'),
    Dropout(0.3),
    Dense(32, activation='relu'),
    Dropout(0.3),
    Dense(1, activation='sigmoid')
])


model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
history = model.fit(X_train_resampled, y_train_resampled,
                    epochs=50,
                    batch_size=32,
                    validation_split=0.2,
                    callbacks=[early_stop],
                    shuffle=True,
                    verbose=1)

# Predicting the probabilities and classes
y_prob_nn = model.predict(X_test).ravel()
y_pred_nn = (y_prob_nn >= 0.5).astype(int)

# Evaluation
from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score

print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred_nn))

print("\nClassification Report:")
print(classification_report(y_test, y_pred_nn))

print("ROC AUC Score:", roc_auc_score(y_test, y_prob_nn))

from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt

plt.figure(figsize=(8, 6))

# Logistic Regression Model
y_prob_lr = lr.predict_proba(X_test)[:, 1]
fpr_lr, tpr_lr, _ = roc_curve(y_test, y_prob_lr)
plt.plot(fpr_lr, tpr_lr, label=f"Logistic Regression (AUC = {auc(fpr_lr, tpr_lr):.2f})")

# Decision Tree Model
y_prob_dt = dt.predict_proba(X_test)[:, 1]
fpr_dt, tpr_dt, _ = roc_curve(y_test, y_prob_dt)
plt.plot(fpr_dt, tpr_dt, label=f"Decision Tree (AUC = {auc(fpr_dt, tpr_dt):.2f})")

# Random Forest Model
y_prob_rf = rf.predict_proba(X_test)[:, 1]
fpr_rf, tpr_rf, _ = roc_curve(y_test, y_prob_rf)
plt.plot(fpr_rf, tpr_rf, label=f"Random Forest (AUC = {auc(fpr_rf, tpr_rf):.2f})")

# Neural Network Model
y_prob_nn = model.predict(X_test).ravel()
fpr_nn, tpr_nn, _ = roc_curve(y_test, y_prob_nn)
plt.plot(fpr_nn, tpr_nn, label=f"Neural Network (AUC = {auc(fpr_nn, tpr_nn):.2f})")

# Plotting the ROC curve
plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve Comparison")
plt.legend(loc="lower right")
plt.grid()
plt.show()

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

def get_model_metrics(name, y_true, y_pred):
    return {
        "Model": name,
        "Accuracy": accuracy_score(y_true, y_pred),
        "Precision": precision_score(y_true, y_pred),
        "Recall": recall_score(y_true, y_pred),
        "F1 Score": f1_score(y_true, y_pred)
    }

results = []

# Logistic Regression Model
y_pred_lr = lr.predict(X_test)
results.append(get_model_metrics("Logistic", y_test, y_pred_lr))

# Decision Tree Model
y_pred_dt = dt.predict(X_test)
results.append(get_model_metrics("Decision Tree", y_test, y_pred_dt))

# Random Forest Model
y_pred_rf = rf.predict(X_test)
results.append(get_model_metrics("Random Forest", y_test, y_pred_rf))

# Neural Network Model
y_pred_nn = (model.predict(X_test).ravel() >= 0.5).astype(int)
results.append(get_model_metrics("Neural Network", y_test, y_pred_nn))

import pandas as pd
import seaborn as sns

df_results = pd.DataFrame(results)
df_results_melted = df_results.melt(id_vars='Model', var_name='Metric', value_name='Score')

plt.figure(figsize=(10, 6))
sns.barplot(data=df_results_melted, x='Metric', y='Score', hue='Model')
plt.title("Model Comparison: Precision, Recall, F1 Score, Accuracy")
plt.ylim(0, 1)
plt.legend(title="Models")
plt.grid(True)
plt.show()

"""# Model Selection"""

best_model_f1 = df_results.loc[df_results["F1 Score"].idxmax()]

print("Best Model Based on F1 Score:")
print(best_model_f1)

"""### Insight
Logistic Regression could be the best model choice based on F1 score and about not missing churners because of its high recall, however we it comes to the most balanced and strongest all-around performance, Neutral Network is the best choice.
"""

#Selection of the neural network model based on deeper analysis
best_model = df_results[df_results["Model"] == "Neural Network"].iloc[0]

print("Final Selected Model (based on analysis, not just one metric):")
print(best_model)